{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a83a75c6-0c90-45ce-8385-fef7053007b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import imutils\n",
    "import cv2 \n",
    "import imageio\n",
    "from imutils import face_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e78c1255-607b-4386-83d9-ac1978e1fadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_to_bb(rect):\n",
    "    # take a bounding predicted by dlib and convert it\n",
    "    # to the format (x, y, w, h) as we would normally do\n",
    "    # with OpenCV\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "\n",
    "    # return a tuple of (x, y, w, h)\n",
    "    return (x, y, w, h)\n",
    "\n",
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    # initialize the list of (x, y)-coordinates\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "\n",
    "    # loop over the 68 facial landmarks and convert them\n",
    "    # to a 2-tuple of (x, y)-coordinates\n",
    "    for i in range(0, 68):\n",
    "    \tcoords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\n",
    "    # return the list of (x, y)-coordinates\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e850fb6-8311-4755-ad1b-adf63b263056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_save_image(img, img_path, write_img_path, img_name):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('./MIRACL-VC1_all_in_one/shape_predictor_68_face_landmarks.dat')\n",
    "    # load the input image, resize it, and convert it to grayscale\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    image = imutils.resize(image, width=500)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 1)\n",
    "    if len(rects) > 1:\n",
    "        print( \"ERROR: more than one face detected\")\n",
    "        return\n",
    "    if len(rects) < 1:\n",
    "        print( \"ERROR: no faces detected\")\n",
    "        return\n",
    "\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        name, i, j = 'mouth', 48, 68\n",
    "        clone = gray.copy()\n",
    "\n",
    "        (x, y, w, h) = cv2.boundingRect(np.array([shape[i:j]]))\n",
    "        \n",
    "        # Calculate aspect ratio of the ROI\n",
    "        aspect_ratio = w / h\n",
    "\n",
    "        # Resize ROI to fit within a 40x40 box without distorting the aspect ratio\n",
    "        if aspect_ratio > 1:  # Width > Height\n",
    "            new_w = 40\n",
    "            new_h = int(40 / aspect_ratio)\n",
    "        else:  # Height >= Width\n",
    "            new_w = int(40 * aspect_ratio)\n",
    "            new_h = 40\n",
    "\n",
    "        roi = gray[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Pad the resized ROI to make it 40x40\n",
    "        pad_top = (40 - new_h) // 2\n",
    "        pad_bottom = 40 - new_h - pad_top\n",
    "        pad_left = (40 - new_w) // 2\n",
    "        pad_right = 40 - new_w - pad_left\n",
    "        roi = cv2.copyMakeBorder(roi, pad_top, pad_bottom, pad_left, pad_right, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "        print('cropped/' + write_img_path)\n",
    "        imageio.imwrite('cropped/' + write_img_path, roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f44db93-8ccc-43af-85c3-4d301d8782c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./MIRACL-VC1_all_in_one\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mdlib\u001b[49m\u001b[38;5;241m.\u001b[39mshape_predictor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./MIRACL-VC1_all_in_one/shape_predictor_68_face_landmarks.dat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dlib' is not defined"
     ]
    }
   ],
   "source": [
    "os.listdir('./MIRACL-VC1_all_in_one')\n",
    "predictor = dlib.shape_predictor('./MIRACL-VC1_all_in_one/shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d149e9fb-33b5-4430-b166-a9d8ad466aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "people = ['F01','F02','F04','F05','F06','F07','F08','F09', 'F10','F11','M01','M02','M04','M07','M08']\n",
    "data_types = ['words']\n",
    "folder_enum = ['01','02','03','04','05','06','07','08','09','10']\n",
    "instances = ['01','02','03','04','05','06','07','08','09','10']\n",
    "\n",
    "words = ['Stop navigation', 'Excuse me', 'I am sorry', 'Thank you', 'Good bye', 'I love this game', 'Nice to meet you', 'You are welcome', 'How are you', 'Have a good time']          \n",
    "words_di = {i:words[i] for i in range(len(words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0057ee5-2952-4e14-9937-542741230c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crearting new folder for cropped images\n",
    "#if not os.path.exists('cropped'):\n",
    "    #os.mkdir('cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9c09895-47fd-4ee8-8f71-a6842709e310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def crop_one_person():      \n",
    "    \n",
    "#    people = ['F01','F02','F04','F05','F06','F07','F08','F09', 'F10','F11','M01','M02','M04','M07','M08']\n",
    "#    data_types = ['words']\n",
    "#    folder_enum = ['01','02']\n",
    "#    instances = ['01','02']\n",
    "\n",
    "    i = 1\n",
    "    for person_ID in people:\n",
    "        if not os.path.exists('cropped/' + person_ID ):\n",
    "            os.mkdir('cropped/' + person_ID + '/')\n",
    "\n",
    "        for data_type in data_types:\n",
    "            if not os.path.exists('cropped/' + person_ID + '/' + data_type):\n",
    "                os.mkdir('cropped/' + person_ID + '/' + data_type)\n",
    "\n",
    "            for phrase_ID in folder_enum:\n",
    "                if not os.path.exists('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID):\n",
    "                    # F01/phrases/01\n",
    "                    os.mkdir('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID)\n",
    "\n",
    "                for instance_ID in instances:\n",
    "                    # F01/phrases/01/01\n",
    "                    directory = './MIRACL-VC1_all_in_one/' + person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID + '/'\n",
    "                    dir_temp = person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID + '/'\n",
    "                    print(directory)\n",
    "                    filelist = os.listdir(directory)\n",
    "                    if not os.path.exists('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID):\n",
    "                        os.mkdir('cropped/' + person_ID + '/' + data_type + '/' + phrase_ID + '/' + instance_ID)\n",
    "\n",
    "                        for img_name in filelist:\n",
    "                            if img_name.startswith('color'):\n",
    "                                image = imageio.imread(directory + '' + img_name)\n",
    "                                crop_and_save_image(image, directory + '' + img_name,\n",
    "                                                    dir_temp + '' + img_name, img_name)\n",
    "\n",
    "    print(f'Iteration : {i}')\n",
    "    i += 1\n",
    "  #  shutil.rmtree('cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6eed098-414d-4dad-8a3a-503900a0ee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./MIRACL-VC1_all_in_one/F01/words/01/01/\n",
      "./MIRACL-VC1_all_in_one/F01/words/01/02/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kisho\\AppData\\Local\\Temp\\ipykernel_6464\\4028004350.py:35: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(directory + '' + img_name)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m7\u001b[39m):\n\u001b[0;32m      5\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mcrop_one_person\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      8\u001b[0m     times \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (t2 \u001b[38;5;241m-\u001b[39m t1)\n",
      "Cell \u001b[1;32mIn[14], line 36\u001b[0m, in \u001b[0;36mcrop_one_person\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m img_name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     35\u001b[0m                             image \u001b[38;5;241m=\u001b[39m imageio\u001b[38;5;241m.\u001b[39mimread(directory \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m img_name)\n\u001b[1;32m---> 36\u001b[0m                             \u001b[43mcrop_and_save_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mdir_temp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIteration : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m, in \u001b[0;36mcrop_and_save_image\u001b[1;34m(img, img_path, write_img_path, img_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcrop_and_save_image\u001b[39m(img, img_path, write_img_path, img_name):\n\u001b[1;32m----> 2\u001b[0m     detector \u001b[38;5;241m=\u001b[39m \u001b[43mdlib\u001b[49m\u001b[38;5;241m.\u001b[39mget_frontal_face_detector()\n\u001b[0;32m      3\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mshape_predictor(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./MIRACL-VC1_all_in_one/shape_predictor_68_face_landmarks.dat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# load the input image, resize it, and convert it to grayscale\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dlib' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "os.mkdir('cropped1')\n",
    "times = 0\n",
    "for _ in range(7):\n",
    "    t1 = time.time()\n",
    "    crop_one_person()\n",
    "    t2 = time.time()\n",
    "    times += (t2 - t1)\n",
    "\n",
    "print(\"Average time over 7 iterations : \", times/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e423a8b0-a895-405e-aa04-5f5f7c75d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def batch_normalization(orig_seq):\n",
    "    orig_len = len(orig_seq)\n",
    "    new_seq = []\n",
    "    for i in range(36):\n",
    "        new_index = int((i * orig_len) / 36)\n",
    "        new_seq.append(orig_seq[new_index])\n",
    "    return new_seq\n",
    "\n",
    "def concatenate_images(directory):\n",
    "    images = []\n",
    "    filelist = sorted(os.listdir(directory))\n",
    "    for img_name in filelist:\n",
    "        if img_name.endswith('.jpg'):\n",
    "            img_path = os.path.join(directory, img_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (40, 40))  # Resize to 40x40 if not already resized\n",
    "            images.append(img)\n",
    "\n",
    "    # Apply batch normalization to the images\n",
    "    normalized_images = batch_normalization(images)\n",
    "\n",
    "    # Create a blank canvas for the concatenated image\n",
    "    concatenated_image = np.zeros((240, 240), dtype=np.uint8)\n",
    "\n",
    "    # Arrange the normalized images into a 4x4 grid\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            idx = i * 6 + j\n",
    "            img = normalized_images[idx]\n",
    "            row_start = i * 40\n",
    "            row_end = row_start + 40\n",
    "            col_start = j * 40\n",
    "            col_end = col_start + 40\n",
    "            concatenated_image[row_start:row_end, col_start:col_end] = img\n",
    "\n",
    "    return concatenated_image\n",
    "\n",
    "# Example usage:\n",
    "#person_ID = 'F01'\n",
    "#data_type = 'words'\n",
    "#phrase_ID = '01'\n",
    "#instance_ID = '01'\n",
    "#directory = f'cropped/{person_ID}/{data_type}/{phrase_ID}/{instance_ID}'\n",
    "#concatenated_image = concatenate_images(directory)\n",
    "\n",
    "# Display the concatenated image\n",
    "#cv2.imshow('Concatenated Image', concatenated_image)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6a7f96e-e928-456c-8e1f-276a3e818630",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m root_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcropped\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Directory containing cropped images\u001b[39;00m\n\u001b[0;32m     22\u001b[0m save_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcatenated_images\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Directory to save concatenated images\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43msave_concatenated_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m, in \u001b[0;36msave_concatenated_images\u001b[1;34m(root_dir, save_dir)\u001b[0m\n\u001b[0;32m     13\u001b[0m instance_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(phrase_dir, instance_ID)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(instance_dir):\n\u001b[1;32m---> 15\u001b[0m     concatenated_image \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, person_ID, data_type, phrase_ID, instance_ID \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(save_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[18], line 23\u001b[0m, in \u001b[0;36mconcatenate_images\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     20\u001b[0m         images\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Apply batch normalization to the images\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m normalized_images \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_normalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Create a blank canvas for the concatenated image\u001b[39;00m\n\u001b[0;32m     26\u001b[0m concatenated_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m240\u001b[39m, \u001b[38;5;241m240\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m, in \u001b[0;36mbatch_normalization\u001b[1;34m(orig_seq)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m36\u001b[39m):\n\u001b[0;32m      8\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((i \u001b[38;5;241m*\u001b[39m orig_len) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m36\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     new_seq\u001b[38;5;241m.\u001b[39mappend(\u001b[43morig_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_index\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_seq\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "person_ID = ['F01','F02','F04','F05','F06','F07','F08','F09', 'F10','F11','M01','M02','M04','M07','M08']\n",
    "def save_concatenated_images(root_dir, save_dir):\n",
    "    for person_ID in os.listdir(root_dir):\n",
    "        person_dir = os.path.join(root_dir, person_ID)\n",
    "        if os.path.isdir(person_dir):\n",
    "            for data_type in os.listdir(person_dir):\n",
    "                data_dir = os.path.join(person_dir, data_type)\n",
    "                if os.path.isdir(data_dir):\n",
    "                    for phrase_ID in os.listdir(data_dir):\n",
    "                        phrase_dir = os.path.join(data_dir, phrase_ID)\n",
    "                        if os.path.isdir(phrase_dir):\n",
    "                            for instance_ID in os.listdir(phrase_dir):\n",
    "                                instance_dir = os.path.join(phrase_dir, instance_ID)\n",
    "                                if os.path.isdir(instance_dir):\n",
    "                                    concatenated_image = concatenate_images(instance_dir)\n",
    "                                    save_path = os.path.join(save_dir, person_ID, data_type, phrase_ID, instance_ID + '.jpg')\n",
    "                                    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "                                    cv2.imwrite(save_path, concatenated_image)\n",
    "\n",
    "# Example usage:\n",
    "root_directory = 'cropped'  # Directory containing cropped images\n",
    "save_directory = 'concatenated_images'  # Directory to save concatenated images\n",
    "save_concatenated_images(root_directory, save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384685e-9f2e-4545-8525-e43284042991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
